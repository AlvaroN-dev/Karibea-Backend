# ğŸ” AUDITORÃA DE ARQUITECTURA - KARIBEA BACKEND

## ğŸ“‹ Resumen Ejecutivo

**Fecha de AuditorÃ­a:** Junio 2025  
**Auditor:** Senior Software Architect / DevOps Engineer  
**Objetivo:** Validar configuraciÃ³n para despliegue PRE-PROD/STAGE en VM Ãºnica  
**Plataforma Target:** Google Cloud Compute Engine (VM Ãºnica)

---

## âš ï¸ ADVERTENCIAS IMPORTANTES

### ğŸ”´ ESTO ES UN ENTORNO PRE-PROD/STAGE

Esta configuraciÃ³n estÃ¡ optimizada para **pruebas y staging**, NO para producciÃ³n real con alta disponibilidad.

| Aspecto | PRE-PROD (Esta Config) | PRODUCCIÃ“N (Recomendado) |
|---------|------------------------|--------------------------|
| Infraestructura | VM Ãºnica | GKE + Cloud SQL + Managed Kafka |
| PostgreSQL | Container Docker | Cloud SQL (HA) |
| Kafka | 3 nodos en misma VM | Confluent Cloud / Cloud Pub/Sub |
| Alta Disponibilidad | âŒ No | âœ… SÃ­ |
| Escalado | Vertical (limitado) | Horizontal (ilimitado) |
| Recovery | Manual | AutomÃ¡tico |
| SLA | ~95% | 99.9%+ |

---

## ğŸ“Š Consumo de Recursos por Componente

### Tabla de AsignaciÃ³n de Memoria

| Componente | mem_limit | JVM Heap | CPUs | JustificaciÃ³n |
|------------|-----------|----------|------|---------------|
| **PostgreSQL** | 1536M | N/A | 1.0 | shared_buffers=384MB + cache + connections |
| **Kafka-0** | 768M | 256-512m | 0.5 | Broker con controller |
| **Kafka-1** | 768M | 256-512m | 0.5 | Broker con controller |
| **Kafka-2** | 768M | 256-512m | 0.5 | Broker con controller |
| **Elasticsearch** | 1024M | 512m | 0.5 | Single-node dev mode |
| **Config Server** | 384M | 64-256m | 0.3 | TrÃ¡fico bajo, solo configs |
| **Eureka** | 384M | 64-256m | 0.3 | Registry service |
| **Gateway** | 512M | 128-384m | 0.5 | Punto de entrada, alto trÃ¡fico |
| **Servicios (Ã—13)** | 400M | 96-320m | 0.3 | Workload estÃ¡ndar cada uno |

### CÃ¡lculo de Recursos Totales

```
Infraestructura:
  PostgreSQL:      1,536 MB
  Kafka (Ã—3):      2,304 MB (768 Ã— 3)
  Elasticsearch:   1,024 MB
  Config Server:     384 MB
  Eureka:            384 MB
  Gateway:           512 MB
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Subtotal:        6,144 MB

Microservicios (Ã—13):
  400 MB Ã— 13 =    5,200 MB

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOTAL:            11,344 MB (~11.1 GB)

RecomendaciÃ³n VM: 12-16 GB RAM
```

---

## âœ… Problemas Corregidos en esta AuditorÃ­a

### 1. ğŸ³ Resource Limits (Docker Compose Classic)

**Problema:** `deploy.resources` solo funciona en Docker Swarm mode.

**Antes (INCORRECTO):**
```yaml
deploy:
  resources:
    limits:
      memory: 512M
    reservations:
      memory: 256M
```

**DespuÃ©s (CORRECTO):**
```yaml
mem_limit: 512M
cpus: 0.5
```

**VerificaciÃ³n:** Los lÃ­mites reales se aplican con:
```bash
docker stats --format "table {{.Name}}\t{{.MemUsage}}\t{{.CPUPerc}}"
```

---

### 2. ğŸ§  OptimizaciÃ³n de Memoria JVM

**Problema:** Misma configuraciÃ³n JVM para todos los servicios.

**SoluciÃ³n:** DiferenciaciÃ³n por tipo de servicio:

| Tipo de Servicio | JAVA_OPTS |
|------------------|-----------|
| Config/Eureka | `-Xms64m -Xmx256m -XX:+UseG1GC` |
| Gateway | `-Xms128m -Xmx384m -XX:+UseG1GC` |
| Business Services | `-Xms96m -Xmx320m -XX:+UseG1GC` |

**CÃ¡lculo:**
- `mem_limit` = JVM Heap + ~120MB overhead (metaspace, threads, native)
- Gateway 512MB = 384MB heap + 128MB overhead
- Services 400MB = 320MB heap + 80MB overhead

---

### 3. ğŸ”’ ExposiciÃ³n de Puertos

**Problema:** Todos los servicios exponÃ­an puertos al host.

**Antes (INSEGURO):**
```yaml
microservice-identity:
  ports:
    - "8082:8082"
microservice-catalog:
  ports:
    - "8083:8083"
# ... todos expuestos
```

**DespuÃ©s (SEGURO):**
```yaml
# SOLO Gateway expone puerto
microservice-gateway:
  ports:
    - "8080:8080"

# Resto usa red interna Docker
microservice-identity:
  networks:
    - karibea-network
  # NO ports:
```

**Beneficios:**
- âœ… Superficie de ataque reducida
- âœ… Arquitectura de microservicios correcta (todo pasa por Gateway)
- âœ… Rate limiting y autenticaciÃ³n centralizados

---

### 4. ğŸ˜ PostgreSQL Sizing

**Problema:** `effective_cache_size` mayor que memoria del container.

**Antes (INCORRECTO):**
```yaml
command: >
  -c effective_cache_size=2GB  # Container con 1GB!
```

**DespuÃ©s (CORRECTO):**
```yaml
mem_limit: 1536M
command: >
  -c shared_buffers=384MB        # 25% de mem_limit
  -c effective_cache_size=1GB    # ~65% de mem_limit
  -c work_mem=16MB
  -c maintenance_work_mem=128MB
  -c max_connections=150
```

**FÃ³rmula de tuning:**
- `shared_buffers` = 25% de RAM del container
- `effective_cache_size` = 65-75% de RAM del container
- `max_connections` = (servicios Ã— pool_size) + buffer

---

### 5. ğŸŠ HikariCP Connection Pool

**Problema:** Pools muy grandes agotan conexiones PostgreSQL.

**CÃ¡lculo:**
```
13 servicios Ã— 5 conexiones = 65 conexiones base
Con picos: hasta 130+ conexiones
PostgreSQL max_connections=100 â†’ âŒ AGOTAMIENTO
```

**SoluciÃ³n:**
```yaml
# .env
SPRING_DATASOURCE_HIKARI_MAXIMUM_POOL_SIZE=3
SPRING_DATASOURCE_HIKARI_MINIMUM_IDLE=1
```

**Nuevo cÃ¡lculo:**
```
13 servicios Ã— 3 conexiones = 39 conexiones
Con buffer para admin/monitoring: ~50
PostgreSQL max_connections=150 â†’ âœ… SUFICIENTE
```

---

### 6. ğŸ“¨ Kafka en VM Ãšnica

**Problema:** 3 brokers Kafka en misma VM no provee redundancia real.

**Realidad:**
- âŒ Si la VM falla, todo Kafka falla
- âŒ Los 3 brokers compiten por I/O de disco
- âŒ No hay aislamiento de fallas

**Mitigaciones aplicadas:**
```yaml
kafka-0:
  mem_limit: 768M          # LÃ­mites estrictos
  cpus: 0.5                # CPU fair-share
  environment:
    KAFKA_HEAP_OPTS: -Xms256m -Xmx512m
    
  # Replication settings reducidos para single-VM
  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
```

**Advertencia:** Para producciÃ³n usar:
- Google Cloud Pub/Sub, o
- Confluent Cloud (managed Kafka), o
- Al menos 3 VMs separadas para los brokers

---

## ğŸ“ Archivos Modificados

| Archivo | Cambios |
|---------|---------|
| `docker-compose.prod.yml` | Recreado con `mem_limit/cpus`, solo Gateway expuesto |
| `docker-compose.dev.yml` | Recreado con mismos principios de auditorÃ­a |
| `.env` | HikariCP ajustado, variables de recursos agregadas |

---

## ğŸ”§ Comandos de VerificaciÃ³n

### Verificar lÃ­mites de memoria activos
```bash
docker stats --format "table {{.Name}}\t{{.MemUsage}}\t{{.MemPerc}}\t{{.CPUPerc}}"
```

### Verificar conexiones PostgreSQL
```bash
docker exec postgres psql -U postgres -c "SELECT count(*) FROM pg_stat_activity;"
```

### Verificar estado de Kafka
```bash
docker exec kafka-0 kafka-metadata.sh --snapshot /var/lib/kafka/data/__cluster_metadata-0/00000000000000000000.log --command "describe"
```

### Verificar health de todos los servicios
```bash
docker compose -f docker-compose.prod.yml ps
```

### Verificar logs de errores
```bash
docker compose -f docker-compose.prod.yml logs --tail=100 | grep -i error
```

---

## ğŸ“ˆ Monitoreo Recomendado

Para PRE-PROD se recomienda agregar:

1. **Prometheus + Grafana** para mÃ©tricas
2. **Actuator endpoints** habilitados en cada servicio
3. **Alert rules** para:
   - Memory usage > 80%
   - CPU usage > 70%
   - Conexiones DB > 100
   - Kafka consumer lag > 1000

---

## ğŸš€ Siguiente Paso: ProducciÃ³n Real

Cuando estÃ© listo para producciÃ³n, migrar a:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Google Cloud Platform                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Cloud Load   â”‚â”€â”€â”€â–¶â”‚  GKE Cluster (Autopilot)          â”‚  â”‚
â”‚  â”‚ Balancer     â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚Gateway  â”‚ â”‚Services â”‚ (Ã—N)     â”‚  â”‚
â”‚                       â”‚  â”‚(3 pods) â”‚ â”‚(3 pods) â”‚          â”‚  â”‚
â”‚                       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚                       â”‚
â”‚  â”‚ Cloud SQL    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚  â”‚ (PostgreSQL) â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ HA enabled   â”‚    â”‚  Confluent Cloud / Pub/Sub        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  (Managed Kafka)                  â”‚  â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Checklist de ValidaciÃ³n

- [x] Todos los `deploy.resources` reemplazados por `mem_limit/cpus`
- [x] Solo Gateway expone puerto 8080
- [x] JVM optimizada por tipo de servicio
- [x] PostgreSQL tuning acorde a container memory
- [x] HikariCP pool size reducido (3 conexiones por servicio)
- [x] Kafka heap limitado (-Xms256m -Xmx512m)
- [x] Red Docker interna para comunicaciÃ³n inter-servicios
- [x] Healthchecks configurados para todos los servicios
- [x] Variables de entorno sin valores por defecto (sin `:-default`)
- [x] DocumentaciÃ³n de advertencias PRE-PROD vs PROD

---

**AuditorÃ­a completada.** âœ…

*Este documento debe ser revisado antes de cualquier despliegue y actualizado cuando se realicen cambios significativos en la arquitectura.*
